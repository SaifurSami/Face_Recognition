{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n",
      " found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the face detector and shape predictor\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "dlib_facelandmark = dlib.shape_predictor(\"./detector/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load the Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Create a directory to save the frames\n",
    "output_dir = 'saved_frames'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the desired frame rate (fps)\n",
    "desired_fps = 12\n",
    "cap.set(cv2.CAP_PROP_FPS, desired_fps)\n",
    "\n",
    "# Frame count\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = hog_face_detector(frame)\n",
    "    if len(faces) == 0:\n",
    "        # If no faces are detected, append an empty frame\n",
    "        continue\n",
    "    \n",
    "    temp = frame.copy()\n",
    "    # Draw rectangle around the faces and save the frame if faces are detected\n",
    "    for face in faces:\n",
    "        frame_count += 1\n",
    "        face_landmarks = dlib_facelandmark(frame, face)\n",
    "        for n in range(0, 68):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            cv2.circle(temp, (x, y), 1, (255, 255, 255), -1)\n",
    "        # Save the frame with faces\n",
    "        frame_filename = os.path.join(output_dir, f'frame_{frame_count}.jpg')\n",
    "        \n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        \n",
    "        \n",
    "        image = face_recognition.load_image_file(frame_filename)\n",
    "        unknown_encodings = face_recognition.face_encodings(image)\n",
    "        \n",
    "        # print(unknown_encodings)\n",
    "        \n",
    "        if unknown_encodings:\n",
    "            # Load each image file in the known images directory\n",
    "            images_dir = 'Images'\n",
    "            for filename in os.listdir(images_dir):\n",
    "                if filename.endswith(('.jpg', '.jpeg', '.png')):  # Consider image files only\n",
    "                    image_path = os.path.join(images_dir, filename)\n",
    "                    # Load the image\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    # Get face encodings\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        # Compare faces\n",
    "                        results = face_recognition.compare_faces(unknown_encodings[0], encodings)\n",
    "                        # print(f'{results}', end=\"\")\n",
    "                        if results[0]:\n",
    "                            print(f\" found\\n\")\n",
    "                            break\n",
    "                        # else:\n",
    "                            # print(f'not Found\\n')\n",
    "\n",
    "        \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', temp)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a working webcam capture object\n",
    "# def get_video_capture():\n",
    "#     video_capture = cv2.VideoCapture(0)\n",
    "#     if video_capture.isOpened():\n",
    "#         print(f\"Camera found at index {i}\")\n",
    "#         return video_capture\n",
    "#     video_capture.release()\n",
    "#     # return None\n",
    "\n",
    "# # Get a reference to webcam\n",
    "# video_capture = get_video_capture()\n",
    "# if video_capture is None:\n",
    "#     print(\"No camera found\")\n",
    "#     exit()\n",
    "\n",
    "# Directory containing known images\n",
    "images_dir = \"saved_frames\"\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Load each image file in the known images directory\n",
    "for filename in os.listdir(images_dir):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Consider image files only\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "        # Load the image\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        # Get face encodings\n",
    "        encodings = face_recognition.face_encodings(image)\n",
    "        if encodings:\n",
    "            # Use the first encoding found in the image\n",
    "            known_face_encodings.append(encodings[0])\n",
    "            # Use the filename (without extension) as the name\n",
    "            known_face_names.append(os.path.splitext(filename)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the face detector and shape predictor\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "dlib_facelandmark = dlib.shape_predictor(\"./detector/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load the Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Create a directory to save the frames\n",
    "output_dir = 'saved_frames'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the desired frame rate (fps)\n",
    "desired_fps = 12\n",
    "cap.set(cv2.CAP_PROP_FPS, desired_fps)\n",
    "\n",
    "# Frame count\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = hog_face_detector(frame)\n",
    "    if len(faces) == 0:\n",
    "        # If no faces are detected, append an empty frame\n",
    "        continue\n",
    "    \n",
    "    temp = frame.copy()\n",
    "    # Draw rectangle around the faces and save the frame if faces are detected\n",
    "    for face in faces:\n",
    "        frame_count += 1\n",
    "        face_landmarks = dlib_facelandmark(frame, face)\n",
    "        for n in range(0, 68):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            cv2.circle(temp, (x, y), 1, (255, 255, 255), -1)\n",
    "        # Save the frame with faces\n",
    "        frame_filename = os.path.join(output_dir, f'frame_{frame_count}.jpg')\n",
    "        \n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        \n",
    "        \n",
    "        image = face_recognition.load_image_file(frame_filename)\n",
    "        unknown_encodings = face_recognition.face_encodings(image)\n",
    "        \n",
    "        # print(unknown_encodings)\n",
    "        \n",
    "        if unknown_encodings:\n",
    "            # Load each image file in the known images directory\n",
    "            images_dir = 'Images'\n",
    "            for filename in os.listdir(images_dir):\n",
    "                if filename.endswith(('.jpg', '.jpeg', '.png')):  # Consider image files only\n",
    "                    image_path = os.path.join(images_dir, filename)\n",
    "                    # Load the image\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    # Get face encodings\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        # Compare faces\n",
    "                        results = face_recognition.compare_faces(unknown_encodings[0], encodings)\n",
    "                        # print(f'{results}', end=\"\")\n",
    "                        if results[0]:\n",
    "                            print(f\" found\\n\")\n",
    "                            break\n",
    "                        # else:\n",
    "                            # print(f'not Found\\n')\n",
    "\n",
    "        \n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', temp)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame_101',\n",
       " 'frame_68',\n",
       " 'frame_55',\n",
       " 'frame_2',\n",
       " 'frame_49',\n",
       " 'frame_119',\n",
       " 'frame_23',\n",
       " 'frame_74',\n",
       " 'frame_94',\n",
       " 'frame_31',\n",
       " 'frame_115',\n",
       " 'frame_121',\n",
       " 'frame_71',\n",
       " 'frame_16',\n",
       " 'frame_98',\n",
       " 'frame_56',\n",
       " 'frame_19',\n",
       " 'frame_59',\n",
       " 'frame_47',\n",
       " 'frame_108',\n",
       " 'frame_113',\n",
       " 'frame_117',\n",
       " 'frame_60',\n",
       " 'frame_109',\n",
       " 'frame_58',\n",
       " 'frame_97',\n",
       " 'frame_12',\n",
       " 'frame_106',\n",
       " 'frame_13',\n",
       " 'frame_9',\n",
       " 'frame_62',\n",
       " 'frame_8',\n",
       " 'frame_44',\n",
       " 'frame_6',\n",
       " 'frame_41',\n",
       " 'frame_14',\n",
       " 'frame_33',\n",
       " 'frame_76',\n",
       " 'frame_125',\n",
       " 'frame_107',\n",
       " 'frame_82',\n",
       " 'frame_38',\n",
       " 'frame_89',\n",
       " 'frame_96',\n",
       " 'frame_92',\n",
       " 'frame_65',\n",
       " 'frame_25',\n",
       " 'frame_20',\n",
       " 'frame_122',\n",
       " 'frame_42',\n",
       " 'frame_57',\n",
       " 'frame_124',\n",
       " 'frame_51',\n",
       " 'frame_73',\n",
       " 'frame_100',\n",
       " 'frame_46',\n",
       " 'frame_75',\n",
       " 'frame_39',\n",
       " 'frame_22',\n",
       " 'frame_45',\n",
       " 'frame_26',\n",
       " 'frame_21',\n",
       " 'frame_126',\n",
       " 'frame_34',\n",
       " 'frame_127',\n",
       " 'frame_32',\n",
       " 'frame_93',\n",
       " 'frame_79',\n",
       " 'frame_110',\n",
       " 'frame_3',\n",
       " 'frame_78',\n",
       " 'frame_95',\n",
       " 'frame_81',\n",
       " 'frame_70',\n",
       " 'frame_116',\n",
       " 'frame_90',\n",
       " 'frame_99',\n",
       " 'frame_128',\n",
       " 'frame_29',\n",
       " 'frame_30',\n",
       " 'frame_67',\n",
       " 'frame_63',\n",
       " 'frame_72',\n",
       " 'frame_64',\n",
       " 'frame_40',\n",
       " 'frame_91',\n",
       " 'frame_80',\n",
       " 'frame_102',\n",
       " 'frame_66',\n",
       " 'frame_15',\n",
       " 'frame_17',\n",
       " 'frame_118',\n",
       " 'frame_120',\n",
       " 'frame_53',\n",
       " 'frame_103',\n",
       " 'frame_36',\n",
       " 'frame_69',\n",
       " 'frame_104',\n",
       " 'frame_11',\n",
       " 'frame_123',\n",
       " 'frame_83',\n",
       " 'frame_10',\n",
       " 'frame_111',\n",
       " 'frame_87',\n",
       " 'frame_88',\n",
       " 'frame_50',\n",
       " 'frame_61',\n",
       " 'frame_105',\n",
       " 'frame_86',\n",
       " 'frame_114',\n",
       " 'frame_27',\n",
       " 'frame_54',\n",
       " 'frame_85',\n",
       " 'frame_37',\n",
       " 'frame_35',\n",
       " 'frame_24',\n",
       " 'frame_18',\n",
       " 'frame_48',\n",
       " 'frame_112',\n",
       " 'frame_43',\n",
       " 'frame_52',\n",
       " 'frame_84',\n",
       " 'frame_77',\n",
       " 'frame_28']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_face_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Check if frame is captured successfully\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame from webcam. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rony-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
